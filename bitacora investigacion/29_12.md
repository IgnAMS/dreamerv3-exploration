# Meeting 29/12/2025

Topics of the meeting:
- Generated videos from the report of DreamerV3 function.
- Pending tasks.

Meeting observations:
- The report video contains the following elements:
    - 6 columns, each one is a batch.
    
    - 3 rows:
        - First row: real observation image. 
        - Second row: decoded image from stochastic state ($z_t$, $\hat{z}_t$). 
        - Third row: difference between predicted image and the real observation.
    
    - The second row is split in two halves: 
        - The first half the prediction is from the real stochastic state $z_t \sim q_\phi(z_t | h_t, x_t)$. 
        - The second half is from the imagined trajectory $\hat{z}_t \sim p_\phi(\hat{z}_t | h_t)$. 

    - A green border indicates the first half, corresponding to $decode(z_t)$, while the red border indicates the second half, corresponding to $decode(\hat{z}_t)$.

    - The agent presses the button until the cookie reaches the "right corner" (top-left corner). Once the cookie is in this corner, the agent moves towards it.
    
    - The policy corresponds to the sequence of actions from the replay buffer, so the agent may move toward the real cookie while imagining a cookie in a different direction.

    - During imagination, the probability of the cookie appearing in the "right corner" is higher than the others corners. 

    - Occasionally, phantom cookies appear! 

Tasks for the next meeting:
- Run experiments with a deterministic cookie for some runs to verify whether leraning is consistent and not due to coincidence. 

- Study the loss functions and identify the similarities with the intrinsic learning paper.

- Run the new environment where the cookie does not respawn once it is placed on the grid.
 




# Progress 29/12/2025
- Read and summary of the paper curiosity driven exploration. There is the intrinsic reward made the difference between 
the latent of the expected image and the latent of the real image. 
- The deterministics tasks with partial observation didn't learned how to get the cookie
- The cookie without respawn was runned. The algorithm learned how to get to the cookie.

Runs:
- `ts -G 1 bash run_gpu.sh python3 dreamerv3/main.py --logdir ~/logdir/dreamer/cookiepedrodeterministic18x29/size12m/07 --configs cookiepedrodeterministic size12m --run.steps 1000000 --task cookiepedrodeterministic_18x29 --run.save_every 42` and `ts -G 1 bash run_gpu.sh python3 dreamerv3/main.py --logdir ~/logdir/dreamer/cookiepedrodeterministic18x29/size12m/08 --configs cookiepedrodeterministic size12m --run.steps 1000000 --task cookiepedrodeterministic_18x29 --run.save_every 42`.  The algorithm didn't get the cookie.


- `ts -G 1 bash run_gpu.sh python3 dreamerv3/main.py --logdir ~/logdir/dreamer/cookiepedrofullfixed18x29/size12m/01 --configs cookiepedrofullfixed size12m --run.steps 1000000 --task cookiepedrofullfixed_18x29 --run.save_every 42`. The full observation was set wrongly to partial observation. 

- `ts -G 1 bash run_gpu.sh python3 dreamerv3/main.py --logdir ~/logdir/dreamer/cookiepedrofullfixed18x29/size12m/02 --configs cookiepedrofullfixed size12m --run.steps 1000000 --task cookiepedrofullfixed_18x29 --run.save_every 42`. The empty was the incorrect one

- `ts -G 1 bash run_gpu.sh python3 dreamerv3/main.py --logdir ~/logdir/dreamer/cookiepedrofullfixed18x29/size12m/03 --configs cookiepedrofullfixed size12m --run.steps 1000000 --task cookiepedrofullfixed_18x29 --run.save_every 42`. The observation was setted to full observation and the algorithm learned how to get the cookies.


# Progress 02/01/2026
- 